# Qwen 30B Model Profile
name: qwen30b
description: Qwen3 30B GPTQ quantized model optimized for multi-GPU

model: Qwen/Qwen3-30B-A3B-GPTQ-Int4
quantization: gptq
tensor_parallel_size: auto  # Automatically detect and use all GPUs
gpu_memory_utilization: 0.95
max_model_len: 40960
dtype: auto
max_num_batched_tokens: 65536
max_num_seqs: 4
enable_prefix_caching: true
enable_chunked_prefill: true