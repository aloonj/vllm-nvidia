# Qwen3 30B Model Profile
name: qwen3-30b-a3b-gptq-int4
description: Qwen3 30B A3B model with GPTQ Int4 quantization

model: Qwen/Qwen3-30B-A3B-GPTQ-Int4
quantization: gptq
tensor_parallel_size: auto  # Automatically detect and use all GPUs
gpu_memory_utilization: 0.85
max_model_len: 24576
dtype: auto
max_num_batched_tokens: 65536
max_num_seqs: 4
enable_prefix_caching: true
enable_chunked_prefill: true